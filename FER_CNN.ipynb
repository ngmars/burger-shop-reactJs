{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FER_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "14gBCPejj6hDDGD-rui9TtsYs4fzyWL0o",
      "authorship_tag": "ABX9TyP9Hu3WyN+8d7AwkkS+c/Mx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ngmars/Burger-Shop-ReactJs/blob/master/FER_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc_80bXB3Pa6",
        "colab_type": "text"
      },
      "source": [
        "Import Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6wKZHfPowl3d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        },
        "outputId": "08147277-fa2b-4f26-da56-e4d524c80a65"
      },
      "source": [
        "!pip install livelossplot==0.1.2\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "#import utils\n",
        "import os\n",
        "%matplotlib inline\n",
        "import livelossplot\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Flatten, Conv2D\n",
        "from tensorflow.keras.layers import BatchNormalization, Activation, MaxPooling2D\n",
        "from tensorflow.keras.models import Model, Sequential \n",
        "from tensorflow.keras.optimizers import Adam \n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau \n",
        "from tensorflow.keras.utils import plot_model\n",
        "\n",
        "from IPython.display import SVG, Image\n",
        "#from livelossplot import PlotLossesCallback\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow verision: \", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: livelossplot==0.1.2 in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from livelossplot==0.1.2) (3.2.1)\n",
            "Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from livelossplot==0.1.2) (5.2.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.1.2) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.1.2) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.1.2) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.1.2) (0.10.0)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from matplotlib->livelossplot==0.1.2) (1.18.5)\n",
            "Requirement already satisfied: nbformat in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (5.0.7)\n",
            "Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (4.6.3)\n",
            "Requirement already satisfied: traitlets>=4.2.1 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (4.3.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (4.10.1)\n",
            "Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (5.6.1)\n",
            "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (5.3.4)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (0.2.0)\n",
            "Requirement already satisfied: terminado>=0.3.3; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (0.8.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (2.11.2)\n",
            "Requirement already satisfied: tornado>=4 in /usr/local/lib/python3.6/dist-packages (from notebook->livelossplot==0.1.2) (4.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.1->matplotlib->livelossplot==0.1.2) (1.12.0)\n",
            "Requirement already satisfied: jsonschema!=2.5.0,>=2.4 in /usr/local/lib/python3.6/dist-packages (from nbformat->notebook->livelossplot==0.1.2) (2.6.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2.1->notebook->livelossplot==0.1.2) (4.4.2)\n",
            "Requirement already satisfied: ipython>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from ipykernel->notebook->livelossplot==0.1.2) (5.5.0)\n",
            "Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.4.4)\n",
            "Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.6.0)\n",
            "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (1.4.2)\n",
            "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.8.4)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (2.1.3)\n",
            "Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (3.1.5)\n",
            "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook->livelossplot==0.1.2) (0.3)\n",
            "Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->notebook->livelossplot==0.1.2) (19.0.1)\n",
            "Requirement already satisfied: ptyprocess; os_name != \"nt\" in /usr/local/lib/python3.6/dist-packages (from terminado>=0.3.3; sys_platform != \"win32\"->notebook->livelossplot==0.1.2) (0.6.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2->notebook->livelossplot==0.1.2) (1.1.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (4.8.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.8.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.7.5)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (47.3.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot==0.1.2) (20.4)\n",
            "Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook->livelossplot==0.1.2) (0.5.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0->ipykernel->notebook->livelossplot==0.1.2) (0.2.4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n",
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Tensorflow verision:  2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5jftY7n3IhY",
        "colab_type": "text"
      },
      "source": [
        "Plot Sample Image\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GHnEzFg03HPa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "dc31f639-f1f6-42e9-a470-c50e5e6c4682"
      },
      "source": [
        "for expression in os.listdir(\"/content/drive/My Drive/Colab Notebooks/Project/train/\"):\n",
        "  print(str(len(os.listdir(\"/content/drive/My Drive/Colab Notebooks/Project/train/\"+ expression)))+ \" \" + expression + \" Images\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3995 angry Images\n",
            "4965 neutral Images\n",
            "3171 surprise Images\n",
            "436 disgust Images\n",
            "7234 happy Images\n",
            "4097 fear Images\n",
            "4835 sad Images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCfJ3vDSTUZ_",
        "colab_type": "text"
      },
      "source": [
        "Generating training and test data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJp3TpbpTZSL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "4d0c85e7-26b9-4586-ee1c-3ca2369b9d0f"
      },
      "source": [
        "img_size= 48\n",
        "batch_size =64\n",
        "\n",
        "\n",
        "datagen_train= ImageDataGenerator(horizontal_flip=True)\n",
        "train_generator = datagen_train.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/Project/train/\", \n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode='grayscale',\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)\n",
        "datagen_test= ImageDataGenerator(horizontal_flip=True)\n",
        "test_generator = datagen_test.flow_from_directory(\"/content/drive/My Drive/Colab Notebooks/Project/test/\", \n",
        "                                                    target_size=(img_size,img_size),\n",
        "                                                    color_mode='grayscale',\n",
        "                                                    batch_size=batch_size,\n",
        "                                                    class_mode='categorical',\n",
        "                                                    shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 28733 images belonging to 7 classes.\n",
            "Found 7178 images belonging to 7 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJtpirj9XtHq",
        "colab_type": "text"
      },
      "source": [
        "Adding CNN layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38YNgb4fXx5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f597c4bb-e5a4-40ac-bd8d-45e36a0ac74f"
      },
      "source": [
        "#addition of 4 CNN layers \n",
        "model = Sequential()\n",
        "\n",
        "#1-conv \n",
        "model.add(Conv2D(64, (3,3), padding='same', input_shape=(48,48,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#2-conv \n",
        "model.add(Conv2D(128, (5,5), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#3-conv \n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#4-conv \n",
        "model.add(Conv2D(512, (3,3), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(256))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Dense(7, activation='softmax'))\n",
        "\n",
        "opt = Adam(lr=0.0005)\n",
        "model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 48, 48, 64)        640       \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 48, 48, 64)        256       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 48, 48, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 24, 24, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 24, 24, 128)       204928    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 24, 24, 128)       512       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 24, 24, 128)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 12, 12, 512)       590336    \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 12, 12, 512)       2048      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 12, 12, 512)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 6, 6, 512)         2359808   \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 6, 6, 512)         2048      \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 6, 6, 512)         0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 3, 3, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 4608)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 256)               1179904   \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 7)                 1799      \n",
            "=================================================================\n",
            "Total params: 4,343,303\n",
            "Trainable params: 4,340,359\n",
            "Non-trainable params: 2,944\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iN7SV7t-gpBS",
        "colab_type": "text"
      },
      "source": [
        "Training and evaluating model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y2gd7kQ5gsbG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "outputId": "b95528d2-1273-4811-dfdd-648fe66d06df"
      },
      "source": [
        "epochs =10\n",
        "steps_per_epoch= train_generator.n//train_generator.batch_size\n",
        "test_steps=test_generator.n//test_generator.batch_size\n",
        "checkpoint= ModelCheckpoint(\"model_weights.h5\", monitor='val_accuracy', save_weights_only=True,\n",
        "                            mode='max', verbose=1)\n",
        "reduce_lr= ReduceLROnPlateau(monitor='val_loss', factor= 0.1, patience=2, model='auto',\n",
        "                              min_lr=0.00001)\n",
        "callbacks= [ checkpoint, reduce_lr]\n",
        "history = model.fit(x= train_generator, steps_per_epoch= steps_per_epoch, epochs= epochs, validation_data= test_generator, validation_steps=test_steps, callbacks= callbacks)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.7043 - accuracy: 0.3456 \n",
            "Epoch 00001: saving model to model_weights.h5\n",
            "448/448 [==============================] - 12110s 27s/step - loss: 1.7043 - accuracy: 0.3456 - val_loss: 1.6615 - val_accuracy: 0.4148 - lr: 5.0000e-04\n",
            "Epoch 2/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.3978 - accuracy: 0.4689\n",
            "Epoch 00002: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1375s 3s/step - loss: 1.3978 - accuracy: 0.4689 - val_loss: 1.3561 - val_accuracy: 0.4893 - lr: 5.0000e-04\n",
            "Epoch 3/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.2625 - accuracy: 0.5216\n",
            "Epoch 00003: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1361s 3s/step - loss: 1.2625 - accuracy: 0.5216 - val_loss: 1.2298 - val_accuracy: 0.5269 - lr: 5.0000e-04\n",
            "Epoch 4/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.1894 - accuracy: 0.5475\n",
            "Epoch 00004: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1359s 3s/step - loss: 1.1894 - accuracy: 0.5475 - val_loss: 1.1544 - val_accuracy: 0.5607 - lr: 5.0000e-04\n",
            "Epoch 5/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.1469 - accuracy: 0.5677\n",
            "Epoch 00005: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1359s 3s/step - loss: 1.1469 - accuracy: 0.5677 - val_loss: 1.4724 - val_accuracy: 0.4962 - lr: 5.0000e-04\n",
            "Epoch 6/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.1064 - accuracy: 0.5810\n",
            "Epoch 00006: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1364s 3s/step - loss: 1.1064 - accuracy: 0.5810 - val_loss: 1.2154 - val_accuracy: 0.5582 - lr: 5.0000e-04\n",
            "Epoch 7/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.0288 - accuracy: 0.6120\n",
            "Epoch 00007: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1364s 3s/step - loss: 1.0288 - accuracy: 0.6120 - val_loss: 1.0297 - val_accuracy: 0.6136 - lr: 5.0000e-05\n",
            "Epoch 8/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 1.0070 - accuracy: 0.6212\n",
            "Epoch 00008: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1355s 3s/step - loss: 1.0070 - accuracy: 0.6212 - val_loss: 1.0266 - val_accuracy: 0.6222 - lr: 5.0000e-05\n",
            "Epoch 9/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.9946 - accuracy: 0.6258\n",
            "Epoch 00009: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1354s 3s/step - loss: 0.9946 - accuracy: 0.6258 - val_loss: 1.0293 - val_accuracy: 0.6151 - lr: 5.0000e-05\n",
            "Epoch 10/10\n",
            "448/448 [==============================] - ETA: 0s - loss: 0.9872 - accuracy: 0.6278\n",
            "Epoch 00010: saving model to model_weights.h5\n",
            "448/448 [==============================] - 1357s 3s/step - loss: 0.9872 - accuracy: 0.6278 - val_loss: 1.0255 - val_accuracy: 0.6194 - lr: 5.0000e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIk63POLyNZ7",
        "colab_type": "text"
      },
      "source": [
        "Saving it as Json File"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BJFQgvryQX-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_json= model.to_json()\n",
        "with open(\"model.json\",\"w\") as json_file:\n",
        "  json_file.write(model_json)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}